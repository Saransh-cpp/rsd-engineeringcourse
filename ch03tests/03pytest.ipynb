{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3851f8ca",
   "metadata": {},
   "source": [
    "## Testing frameworks\n",
    "\n",
    "### Why use testing frameworks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01eae6",
   "metadata": {},
   "source": [
    "Frameworks should simplify our lives:\n",
    "\n",
    "* Should be easy to add simple test\n",
    "* Should be possible to create complex test:\n",
    "    * Fixtures\n",
    "    * Setup/Tear down\n",
    "    * Parameterized tests (same test, mostly same input)\n",
    "* Find all our tests in a complicated code-base \n",
    "* Run all our tests with a quick command\n",
    "* Run only some tests, e.g. ``test --only \"tests about fields\"``\n",
    "* **Report failing tests**\n",
    "* Additional goodies, such as code coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afb7a4",
   "metadata": {},
   "source": [
    "### Common testing frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddf1eb",
   "metadata": {},
   "source": [
    "* Language agnostic: [CTest](http://www.cmake.org/cmake/help/v2.8.12/ctest.html)\n",
    "  * Test runner for executables, bash scripts, etc...\n",
    "  * Great for legacy code hardening\n",
    "    \n",
    "\n",
    "* C unit-tests:\n",
    "    * all c++ frameworks,\n",
    "    * [Check](https://libcheck.github.io/check/),\n",
    "    * [CUnit](http://cunit.sourceforge.net)\n",
    "\n",
    "\n",
    "* C++ unit-tests:\n",
    "    * [CppTest](http://cpptest.sourceforge.net/),\n",
    "    * [Boost::Test](http://www.boost.org/doc/libs/1_55_0/libs/test/doc/html/index.html),\n",
    "    * [google-test](https://code.google.com/p/googletest/),\n",
    "    * [Catch](https://github.com/philsquared/Catch) (best)\n",
    "\n",
    "\n",
    "* Python unit-tests:\n",
    "    * [nose](https://nose.readthedocs.org/en/latest/) includes test discovery, coverage, etc\n",
    "    * [unittest](https://docs.python.org/3/library/unittest.html) comes with standard python library\n",
    "    * [pytest](https://docs.pytest.org/en/latest/index.html), branched off of nose\n",
    "\n",
    "\n",
    "* R unit-tests:\n",
    "    * [RUnit](http://cran.r-project.org/web/packages/RUnit/index.html),\n",
    "    * [svUnit](http://cran.r-project.org/web/packages/svUnit/index.html)\n",
    "    * (works with [SciViews](http://www.sciviews.org/) GUI)\n",
    "    \n",
    "\n",
    "* Fortran unit-tests:\n",
    "    * [funit](https://rubygems.org/gems/funit),\n",
    "    * [pfunit](http://sourceforge.net/projects/pfunit/)(works with MPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2418eb9",
   "metadata": {},
   "source": [
    "### pytest framework: usage\n",
    "\n",
    "[pytest](https://docs.pytest.org/en/latest/) is a recommended python testing framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b7978",
   "metadata": {},
   "source": [
    "We can use its tools in the notebook for on-the-fly tests in the notebook. This, happily, includes the negative-tests example we were looking for a moment ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74cdfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_only_accept_positive_numbers(number):\n",
    "    # Check input\n",
    "    if number < 0: \n",
    "        raise ValueError(\"Input {} is negative\".format(number))\n",
    "\n",
    "    # Do something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3ff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytest import raises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "with raises(ValueError):\n",
    "    I_only_accept_positive_numbers(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca0d5b",
   "metadata": {},
   "source": [
    "but the real power comes when we write a test file alongside our code files in our homemade packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e652ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p saskatchewan\n",
    "touch saskatchewan/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61355273",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile saskatchewan/overlap.py\n",
    "def overlap(field1, field2):\n",
    "    left1, bottom1, top1, right1 = field1\n",
    "    left2, bottom2, top2, right2 = field2\n",
    "    \n",
    "    overlap_left = max(left1, left2)\n",
    "    overlap_bottom = max(bottom1, bottom2)\n",
    "    overlap_right = min(right1, right2)\n",
    "    overlap_top = min(top1, top2)\n",
    "    # Here's our wrong code again\n",
    "    overlap_height = (overlap_top - overlap_bottom)\n",
    "    overlap_width = (overlap_right - overlap_left)\n",
    "    \n",
    "    return overlap_height * overlap_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile saskatchewan/test_overlap.py\n",
    "from .overlap import overlap\n",
    "\n",
    "def test_full_overlap():\n",
    "    assert overlap((1.,1.,4.,4.), (2.,2.,3.,3.)) == 1.0\n",
    "\n",
    "def test_partial_overlap():\n",
    "    assert overlap((1,1,4,4), (2,2,3,4.5)) == 2.0\n",
    "                 \n",
    "def test_no_overlap():\n",
    "    assert overlap((1,1,4,4), (4.5,4.5,5,5)) == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c64e5",
   "metadata": {
    "attributes": {
     "classes": [
      " bash"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "%%bash --no-raise-error\n",
    "cd saskatchewan\n",
    "pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45816a27",
   "metadata": {},
   "source": [
    "Note that it reported **which** test had failed, how many tests ran, and how many failed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04438b",
   "metadata": {},
   "source": [
    "The symbol `..F` means there were three tests, of which the third one failed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5329f5",
   "metadata": {},
   "source": [
    "Pytest will:\n",
    "\n",
    "* automagically finds files ``test_*.py``\n",
    "* collects all subroutines called ``test_*``\n",
    "* runs tests and reports results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5c3c7",
   "metadata": {},
   "source": [
    "Some options:\n",
    "\n",
    "* help: `pytest --help`\n",
    "* run only tests for a given feature: `pytest -k foo` # tests with 'foo' in the test name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b4a05",
   "metadata": {},
   "source": [
    "## Testing with floating points\n",
    "\n",
    "### Floating points are not reals\n",
    "\n",
    "\n",
    "Floating points are inaccurate representations of real numbers:\n",
    "\n",
    "`1.0 == 0.99999999999999999` is true to the last bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dede136",
   "metadata": {},
   "source": [
    "This can lead to numerical errors during calculations: $1000 (a - b) \\neq 1000a - 1000b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74210aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "1000.0 * 1.0 - 1000.0 * 0.9999999999999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3680b9",
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "1000.0 * (1.0 - 0.9999999999999998)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2061a",
   "metadata": {},
   "source": [
    "*Both* results are wrong: `2e-13` is the correct answer.\n",
    "\n",
    "The size of the error will depend on the magnitude of the floating points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3a58e",
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "1000.0 * 1e5 - 1000.0 * 0.9999999999999998e5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214bac40",
   "metadata": {},
   "source": [
    "The result should be `2e-8`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a630160",
   "metadata": {},
   "source": [
    "### Comparing floating points\n",
    "\n",
    "Use the \"approx\", for a default of a relative tolerance of $10^{-6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b6c9c",
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from pytest import approx\n",
    "assert  0.7 == approx(0.7 + 1e-7) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9816b1b6",
   "metadata": {},
   "source": [
    "Or be more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0ad6d",
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "magnitude = 0.7\n",
    "assert 0.7 == approx(0.701 , rel=0.1, abs=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898399a5",
   "metadata": {},
   "source": [
    "Choosing tolerances is a big area of [debate](https://software-carpentry.org/blog/2014/10/why-we-dont-teach-testing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ac0df",
   "metadata": {},
   "source": [
    "### Comparing vectors of floating points\n",
    "\n",
    "Numerical vectors are best represented using [numpy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fee638",
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array, pi\n",
    "\n",
    "vector_of_reals = array([0.1, 0.2, 0.3, 0.4]) * pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8aafc",
   "metadata": {},
   "source": [
    "Numpy ships with a number of assertions (in ``numpy.testing``) to make\n",
    "comparison easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c65fe5",
   "metadata": {
    "attributes": {
     "classes": [
      " python"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array, pi\n",
    "from numpy.testing import assert_allclose\n",
    "expected = array([0.1, 0.2, 0.3, 0.4, 1e-12]) * pi\n",
    "actual = array([0.1, 0.2, 0.3, 0.4, 2e-12]) * pi\n",
    "actual[:-1] += 1e-6\n",
    "\n",
    "assert_allclose(actual, expected, rtol=1e-5, atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0bd1f",
   "metadata": {},
   "source": [
    "It compares the difference between `actual` and `expected` to ``atol + rtol * abs(expected)``."
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "display_name": "Test Frameworks"
  },
  "jupytext": {
   "main_language": "python",
   "notebook_metadata_filter": "-kernelspec,jupytext,jekyll"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}