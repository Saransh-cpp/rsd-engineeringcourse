{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d195be",
   "metadata": {},
   "source": [
    "## Scaling for containers and algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733dd767",
   "metadata": {},
   "source": [
    "We've seen that NumPy arrays are really useful. Why wouldn't we always want to use them for data which is all the same type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timeit import repeat\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46f6a7",
   "metadata": {},
   "source": [
    "Let's look at appending data into a NumPy array, compared to a plain Python list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_append_to_ndarray(count):\n",
    "    # the function repeat does the same that the `%timeit` magic\n",
    "    # but as a function; so we can plot it.\n",
    "    return repeat('np.append(before, [0])',\n",
    "                  f'import numpy as np; before=np.ndarray({count})',\n",
    "                  number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_append_to_list(count):\n",
    "    return repeat('before.append(0)',\n",
    "                  f'before = [0] * {count}',\n",
    "                  number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.arange(1, 100000, 10000)\n",
    "\n",
    "def plot_time(function, counts, title=None):\n",
    "    plt.plot(counts, list(map(function, counts)))\n",
    "    plt.ylim(bottom=0) \n",
    "    plt.ylabel('seconds')\n",
    "    plt.xlabel('array size')\n",
    "    plt.title(title or function.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_append_to_list, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1827eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_append_to_ndarray, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320bf51",
   "metadata": {},
   "source": [
    "Adding an element to a Python list is way faster! Also, it seems that adding an element to a Python list is independent of the length of the list, but it's not so for a NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acacd40e",
   "metadata": {},
   "source": [
    "How do they perform when accessing an element in the middle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d69a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_lookup_middle_element_in_list(count):\n",
    "    before = [0] * count\n",
    "    def totime():\n",
    "        x = before[count // 2]\n",
    "    return repeat(totime, number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49751b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_lookup_middle_element_in_ndarray(count):\n",
    "    before = np.ndarray(count)\n",
    "    def totime():\n",
    "        x = before[count // 2]\n",
    "    return repeat(totime, number=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_lookup_middle_element_in_list, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4262077",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_lookup_middle_element_in_ndarray, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac30ff",
   "metadata": {},
   "source": [
    "Both scale well for accessing the middle element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb2d2a",
   "metadata": {},
   "source": [
    "What about inserting at the beginning?\n",
    "\n",
    "If we want to insert an element at the beginning of a Python list we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb46207",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ae3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0:0] = [-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f80b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_insert_to_list(count):\n",
    "    return repeat('before[0:0] = [0]',\n",
    "                  f'before = [0] * {count}',number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95622b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_insert_to_list, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72f00",
   "metadata": {},
   "source": [
    "`list` performs **badly** for insertions at the beginning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb951f36",
   "metadata": {},
   "source": [
    "There are containers in Python that work well for insertion at the start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d494bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_insert_to_deque(count):\n",
    "    return repeat('before.appendleft(0)', \n",
    "                  f'from collections import deque; before = deque([0] * {count})',\n",
    "                  number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d033d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_insert_to_deque, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad263b47",
   "metadata": {},
   "source": [
    "But looking up in the middle scales badly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_lookup_middle_element_in_deque(count):\n",
    "    before = deque([0] * count)\n",
    "    def totime():\n",
    "        x = before[count // 2]\n",
    "    return repeat(totime, number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ac810",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_lookup_middle_element_in_deque, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162349b",
   "metadata": {},
   "source": [
    "What is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce257be",
   "metadata": {},
   "source": [
    "Arrays are stored as contiguous memory. Anything which changes the length of the array requires the whole array to be copied elsewhere in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4581f",
   "metadata": {},
   "source": [
    "This copy takes time proportional to the array size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2ac71",
   "metadata": {},
   "source": [
    "![Adding an element to an array - memory representation](./array_memory.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb465d1b",
   "metadata": {},
   "source": [
    "The Python `list` type is **also** an array, but it is allocated with **extra memory**. Only when that memory is exhausted is a copy needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318453e2",
   "metadata": {},
   "source": [
    "![Adding an element to a list - memory representation](list_memory.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9292b5",
   "metadata": {},
   "source": [
    "If the extra memory is typically the size of the current array, a copy is needed every 1/N appends, and costs N to make, so **on average** copies are cheap. We call this **amortized constant time**. \n",
    "\n",
    "This makes it fast to look up values in the middle. However, it may also use more space than is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e5bf0",
   "metadata": {},
   "source": [
    "The deque type works differently: each element contains a pointer to the next. Inserting elements is therefore very cheap, but looking up the Nth element requires traversing N such pointers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6e3f6",
   "metadata": {},
   "source": [
    "![Adding an element to a deque - memory representation](deque_memory.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567db1d2",
   "metadata": {},
   "source": [
    "### Dictionary performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff60e2e",
   "metadata": {},
   "source": [
    "For another example, let's consider the performance of a dictionary versus a couple of other ways in which we could implement an associative array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e564d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evildict:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, akey):\n",
    "        for key, value in self.data:\n",
    "            if key == akey:\n",
    "                return value\n",
    "        raise KeyError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51790d73",
   "metadata": {},
   "source": [
    "If we have an evil dictionary of N elements, how long would it take - on average - to find an element?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5722762",
   "metadata": {},
   "outputs": [],
   "source": [
    "eric = [[\"Name\", \"Eric Idle\"], [\"Job\", \"Comedian\"], [\"Home\", \"London\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eric_evil = evildict(eric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eric_evil[\"Job\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eric_dict = dict(eric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c956df",
   "metadata": {},
   "outputs": [],
   "source": [
    "eric_evil[\"Job\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd58ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"Hello\", \"License\", \"Fish\", \"Eric\", \"Pet\", \"Halibut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(x, key=lambda el: el.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77894e",
   "metadata": {},
   "source": [
    "What if we created a dictionary where we bisect the search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7816b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sorteddict:\n",
    "    def __init__(self, data):\n",
    "        self.data = sorted(data, key = lambda x:x[0])\n",
    "        self.keys = list(map(lambda x:x[0], self.data))\n",
    "        \n",
    "    def __getitem__(self,akey):\n",
    "        from bisect import bisect_left\n",
    "        loc = bisect_left(self.keys, akey)\n",
    "        \n",
    "        if loc != len(self.data):\n",
    "            return self.data[loc][1]\n",
    "        \n",
    "        raise KeyError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "eric_sorted = sorteddict(eric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "eric_sorted[\"Job\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02680ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_dict_generic(ttype, count, number=10000):\n",
    "    from random import randrange\n",
    "    keys = list(range(count))\n",
    "    values = [0] * count\n",
    "    data = ttype(list(zip(keys, values)))\n",
    "    def totime():\n",
    "        x = data[keys[count // 2]]\n",
    "    return repeat(totime, number=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = lambda count: time_dict_generic(dict, count)\n",
    "time_sorted = lambda count: time_dict_generic(sorteddict, count)\n",
    "time_evil = lambda count: time_dict_generic(evildict, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time(time_sorted, counts, title='sorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11693992",
   "metadata": {},
   "source": [
    "We can't really see what's going on here for the sorted example as there's too much noise, but theoretically we should get **logarithmic** asymptotic performance. We write this down as $O(\\ln N)$. This doesn't mean there isn't also a constant term, or a term proportional to something that grows slower (such as $\\ln(\\ln N)$): we always write down just the term that is dominant for large $N$. We saw before that `list` is $O(1)$ for appends, $O(N)$ for inserts. Numpy's `array` is $O(N)$ for appends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.arange(1, 1000, 100)\n",
    "plot_time(time_evil, counts, title='evil')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629433d",
   "metadata": {},
   "source": [
    "The simple check-each-in-turn solution is $O(N)$ - linear time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.arange(1, 100000, 10000)\n",
    "plot_time(time_dict, counts, title='dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9aa30",
   "metadata": {},
   "source": [
    "Python's built-in dictionary is, amazingly, O(1): the time is **independent** of the size of the dictionary.\n",
    "\n",
    "This uses a miracle of programming called the _Hash Table_:\n",
    "you can learn more about [these issues at this video from Harvard University](https://www.youtube.com/watch?v=h2d9b_nEzoA). This material is pretty advanced, but, I think, really interesting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e136c6e",
   "metadata": {},
   "source": [
    "Optional exercise: determine what the asymptotic peformance for the Boids model in terms of the number of Boids. Make graphs to support this. Bonus: how would the performance scale with the number of dimensions?"
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "display_name": "Scaling"
  },
  "jupytext": {
   "main_language": "python",
   "notebook_metadata_filter": "-kernelspec,jupytext,jekyll"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}